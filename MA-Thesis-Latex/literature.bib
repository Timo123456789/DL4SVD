@article{Knoth2017,
   abstract = {1. In 2015, Sub-Saharan Africa witnessed a total of 61 violent conflicts with 20 of them being classified as highly violent conflicts, i.e. wars or limited wars (Heidelberg Institute for Internatio...)},
   author = {Christian Knoth and Edzer Pebesma},
   doi = {10.1080/01431161.2016.1266105},
   issn = {13665901},
   issue = {1},
   journal = {International Journal of Remote Sensing},
   month = {1},
   pages = {273-295},
   publisher = {Taylor & Francis},
   title = {Detecting dwelling destruction in Darfur through object-based change analysis of very high-resolution imagery},
   volume = {38},
   url = {https://www.tandfonline.com/doi/abs/10.1080/01431161.2016.1266105},
   year = {2017},
}
@article{Leblanc2014,
   abstract = {Airborne hyperspectral imaging (HSI) was assessed as a potential tool to locate single grave sites. While airborne HSI has shown to be useful to locate mass graves, it is expected the location of single graves would be an order of magnitude more difficult due to the smaller size and reduced mass of the targets. Two clearings were evaluated (through a blind test) as potential sites for containing at least one set of buried remains. At no time prior to submitting the locations of the potential burial sites from the HSI were the actual locations of the sites released or shared with anyone from the analysis team.The two HSI sensors onboard the aircraft span the range of 408-2524. nm. A range of indicators that exploit the narrow spectral and spatial resolutions of the two complimentary HSI sensors onboard the aircraft were calculated. Based on the co-occurrence of anomalous pixels within the expected range of the indicators three potential areas conforming to our underlying assumptions of the expected spectral responses (and spatial area) were determined. After submission of the predicted burial locations it was revealed that two of the targets were located within GPS error (10. m) of the true burial locations. Furthermore, due to the history of the TPOF site for burial work, investigation of the third target is being considered in the near future. The results clearly demonstrate promise for hyperspectral imaging to aid in the detection of buried remains, however further work is required before these results can justifiably be used in routine scenarios.},
   author = {G. Leblanc and M. Kalacska and R. Soffer},
   doi = {10.1016/J.FORSCIINT.2014.08.020},
   issn = {0379-0738},
   journal = {Forensic Science International},
   keywords = {Airborne remote sensing,Grave detection,Hyperspectral,Single burial},
   month = {12},
   pages = {17-23},
   pmid = {25447169},
   publisher = {Elsevier},
   title = {Detection of single graves by airborne hyperspectral imaging},
   volume = {245},
   year = {2014},
}
@article{Qian2014,
   abstract = {This study evaluates and compares the performance of four machine learning classifiers—support vector machine (SVM), normal Bayes (NB), classification and regression tree (CART) and K nearest neighbor (KNN)—to classify very high resolution images, using an object-based classification procedure. In particular, we investigated how tuning parameters affect the classification accuracy with different training sample sizes. We found that: (1) SVM and NB were superior to CART and KNN, and both could achieve high classification accuracy (>90%); (2) the setting of tuning parameters greatly affected classification accuracy, particularly for the most commonly-used SVM classifier; the optimal values of tuning parameters might vary slightly with the size of training samples;  (3) the size of training sample also greatly affected the classification accuracy, when the size of training sample was less than 125. Increasing the size of training samples generally led to the increase of classification accuracies for all four classifiers. In addition, NB and KNN were more sensitive to the sample sizes. This research provides insights into the selection of classifiers and the size of training samples. It also highlights the importance of the appropriate setting of tuning parameters for different machine learning classifiers and provides useful information for optimizing these parameters.},
   author = {Yuguo Qian and Weiqi Zhou and Jingli Yan and Weifeng Li and Lijian Han},
   doi = {10.3390/RS70100153},
   issn = {2072-4292},
   issue = {1},
   journal = {Remote Sensing 2015, Vol. 7, Pages 153-168},
   keywords = {based classification,machine learning classifiers,object,tuning parameters,urban area,very high resolution image},
   month = {12},
   pages = {153-168},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Comparing Machine Learning Classifiers for Object-Based Land Cover Classification Using Very High Resolution Imagery},
   volume = {7},
   url = {https://www.mdpi.com/2072-4292/7/1/153/htm https://www.mdpi.com/2072-4292/7/1/153},
   year = {2014},
}
@article{Kalacska2006,
   author = {M. Kalacska and L.S. Bell},
   doi = {10.1080/00085030.2006.10757132},
   issn = {0008-5030},
   issue = {1},
   journal = {Canadian Society of Forensic Science Journal},
   month = {1},
   pages = {1-13},
   title = {Remote Sensing as a Tool for the Detection of Clandestine Mass Graves},
   volume = {39},
   year = {2006},
}
@article{Hall2023,
   abstract = {The field of artificial intelligence is seeing the increased application of satellite imagery to analyse poverty in its various manifestations. This nascent but rapidly growing intersection of scholarship holds the potential to help us better understand poverty by leveraging big data and recent advances in machine vision. In this study, we statistically analyse the literature in the expanding field of welfare and poverty predictions from the combination of machine learning and satellite imagery. Here, we apply an integrative review method to extract key data on factors related to the predictive power of welfare. We found that the most important factors correlated to the predictive power of welfare are the number of pre-processing steps employed, the number of datasets used, the type of welfare indicator targeted and the choice of AI model. Studies that used stock measure indicators (assets) as targets achieved better performance—17 percentage points higher—in predicting welfare than those that targeted flow measures (income and consumption) ones. Additionally, we found that the combination of machine learning and deep learning significantly increases predictive power—by as much as 15 percentage points—compared to using either alone. Surprisingly, we found that the spatial resolution of the satellite imagery used is important but not critical to the performance as the relationship is positive but not statistically significant. These findings have important implications for future research in this domain and for anyone aspiring to use the methodology.},
   author = {Ola Hall and Francis Dompae and Ibrahim Wahab and Fred Mawunyo Dzanku},
   doi = {10.1002/JID.3751},
   issn = {1099-1328},
   issue = {7},
   journal = {Journal of International Development},
   keywords = {deep learning,machine learning,poverty analysis,satellite imagery,welfare},
   month = {10},
   pages = {1753-1768},
   publisher = {John Wiley & Sons, Ltd},
   title = {A review of machine learning and satellite imagery for poverty prediction: Implications for development research and applications},
   volume = {35},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1002/jid.3751 \\ https://onlinelibrary.wiley.com/doi/10.1002/jid.3751},
   year = {2023},
}
@misc{Kemper2011,
   abstract = {This paper presents a methodology for the detection of dwelling structures in Darfur camps to estimate the total number of dwellings per camp using GeoEye-1 satellite images. The method is based on a translation of the visual characterization of the searched structures into a morphological image processing chain. Two variants are described: the first variant extracts dwellings fully automatic for enumeration, while the second links the area covered by dwellings to visual interpretation results of representative samples for estimation of the total number of dwellings. Compared to the visual interpretation both produce similar results with correlation coefficients of 0.65 and 0.66 respectively leading to a mean error of 6% in the total number of dwellings. In complex camp settings, the area-based approach might be preferred, since it provides some more control due to the visual interpretation included. Index Terms-Geo-Eye, image analysis, image interpretation, informal settlements, mathematical morphology.},
   author = {Thomas Kemper and Malgorzata Jenerowicz and Martino Pesaresi and Pierre Soille},
   doi = {10.1109/JSTARS.2010.2053700},
   issue = {1},
   journal = {IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING},
   keywords = {Geo-Eye,image analysis,image interpretation,informal settlements,mathematical morphology},
   title = {Enumeration of Dwellings in Darfur Camps From GeoEye-1 Satellite Images Using Mathematical Morphology},
   volume = {4},
   url = {http://ieeexplore.ieee.org.},
   year = {2011},
}


@article{Baatz2000,
   author = {M Baatz and A Schäpe},
   journal = {Angewandte Geographische Informationsverarbeitung},
   pages = {12-23},
   title = {Multiresolution segmentation : an optimization approach for high quality multi-scale image segmentation},
   url = {https://cir.nii.ac.jp/crid/1572261550679971840},
   year = {2000},
}

@article{Benz2004,
   abstract = {Remote sensing from airborne and spaceborne platforms provides valuable data for mapping, environmental monitoring, disaster management and civil and military intelligence. However, to explore the full value of these data, the appropriate information has to be extracted and presented in standard format to import it into geo-information systems and thus allow efficient decision processes. The object-oriented approach can contribute to powerful automatic and semi-automatic analysis for most remote sensing applications. Synergetic use to pixel-based or statistical signal processing methods explores the rich information contents. Here, we explain principal strategies of object-oriented analysis, discuss how the combination with fuzzy methods allows implementing expert knowledge and describe a representative example for the proposed workflow from remote sensing imagery to GIS. The strategies are demonstrated using the first object-oriented image analysis software on the market, eCognition, which provides an appropriate link between remote sensing imagery and GIS. © 2003 Elsevier B.V. All rights reserved.},
   author = {Ursula C. Benz and Peter Hofmann and Gregor Willhauck and Iris Lingenfelder and Markus Heynen},
   doi = {10.1016/J.ISPRSJPRS.2003.10.002},
   issn = {0924-2716},
   issue = {3-4},
   journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
   keywords = {Fuzzy classification,GIS,Multi-resolution segmentation,Object-oriented image analysis,Remote sensing},
   month = {1},
   pages = {239-258},
   publisher = {Elsevier},
   title = {Multi-resolution, object-oriented fuzzy analysis of remote sensing data for GIS-ready information},
   volume = {58},
   year = {2004},
}
@article{Kattenborn2019,
   abstract = {Recent technological advances in remote sensing sensors and platforms, such as high-resolution satellite imagers or unmanned aerial vehicles (UAV), facilitate the availability of fine-grained earth observation data. Such data reveal vegetation canopies in high spatial detail. Efficient methods are needed to fully harness this unpreceded source of information for vegetation mapping. Deep learning algorithms such as Convolutional Neural Networks (CNN) are currently paving new avenues in the field of image analysis and computer vision. Using multiple datasets, we test a CNN-based segmentation approach (U-net) in combination with training data directly derived from visual interpretation of UAV-based high-resolution RGB imagery for fine-grained mapping of vegetation species and communities. We demonstrate that this approach indeed accurately segments and maps vegetation species and communities (at least 84% accuracy). The fact that we only used RGB imagery suggests that plant identification at very high spatial resolutions is facilitated through spatial patterns rather than spectral information. Accordingly, the presented approach is compatible with low-cost UAV systems that are easy to operate and thus applicable to a wide range of users.},
   author = {Teja Kattenborn and Jana Eichel and Fabian Ewald Fassnacht},
   doi = {10.1038/s41598-019-53797-9},
   issn = {20452322},
   issue = {1},
   journal = {Scientific Reports},
   month = {12},
   pmid = {31776370},
   publisher = {Nature Research},
   title = {Convolutional Neural Networks enable efficient, accurate and fine-grained segmentation of plant species and communities from high-resolution UAV imagery},
   volume = {9},
   year = {2019},
}
@misc{Spiegel_article,
   title = {Corona in China: Satellitenbilder von Krematorien deuten auf deutlich mehr Tote hin - DER SPIEGEL},
   url = {https://www.spiegel.de/ausland/corona\--satellitenbilder\--chinesischer\--krematorien-deuten-auf\--deutlich\--mehr\--tote-hin\--a\--c4305852\--d092\--4e54\--a210\--c88b820d564c},
   year = {2023},
}


@misc{Yang2022,
      title={Drone Object Detection Using RGB/IR Fusion}, 
      author={Lizhi Yang and Ruhang Ma and Avideh Zakhor},
      year={2022},
      eprint={2201.03786},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2201.03786}, 
}


@article{Gudius2021,
   abstract = {Satellite imagery is changing the way we understand and predict economic activity in the world. Advancements in satellite hardware and low-cost rocket launches have enabled near-real-time, high-resolution images covering the entire Earth. It is too labour-intensive, time-consuming and expensive for human annotators to analyse petabytes of satellite imagery manually. Current computer vision research exploring this problem still lack accuracy and prediction speed, both significantly important metrics for latency-sensitive automatized industrial applications. Here we address both of these challenges by proposing a set of improvements to the object recognition model design, training and complexity regularisation, applicable to a range of neural networks. Furthermore, we propose a fully convolutional neural network (FCN) architecture optimised for accurate and accelerated object recognition in multispectral satellite imagery. We show that our FCN exceeds human-level performance with state-of-the-art 97.67% accuracy over multiple sensors, it is able to generalize across dispersed scenery and outperforms other proposed methods to date. Its computationally light architecture delivers a fivefold improvement in training time and a rapid prediction, essential to real-time applications. To illustrate practical model effectiveness, we analyse it in algorithmic trading environment. Additionally, we publish a proprietary annotated satellite imagery dataset for further development in this research field. Our findings can be readily implemented for other real-time applications too.},
   author = {Povilas Gudžius and Olga Kurasova and Vytenis Darulis and Ernestas Filatovas},
   doi = {10.1007/S00138-021-01209-2/FIGURES/10},
   issn = {14321769},
   issue = {4},
   journal = {Machine Vision and Applications},
   keywords = {Communications Engineering,Image Processing and Computer Vision,Networks,Pattern Recognition},
   month = {7},
   pages = {1-14},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Deep learning-based object recognition in multispectral satellite imagery for real-time applications},
   volume = {32},
   url = {https://link.springer.com/article/10.1007/s00138-021-01209-2},
   year = {2021}
}


@article{Razakarivony2015,
   abstract = {To cite this version: Sébastien Razakarivony, Frédéric Jurie. Vehicle Detection in Aerial Imagery : A small target detection benchmark. Abstract This paper introduces VEDAI: Vehicle Detection in Aerial Imagery a new database of aerial images provided as a tool to benchmark automatic target recognition algorithms in unconstrained environments. The vehicles contained in the database, in addition of being small, exhibit different variabil-ities such as multiple orientations, lighting/shadowing changes, specularities or occlusions. Furthermore, each image is available in several spectral bands and resolutions. A precise experimental protocol is also given, ensuring that the experimental results obtained by different people can be properly reproduce and compared. Finally, the paper also gives the performance of baseline algorithms on this dataset, for different settings of these algorithms, to illustrate the difficulties of the task and provide baseline comparisons.},
   author = {Sébastien Razakarivony and Frédéric Jurie and Sebastien Razakarivony and Frederic Jurie},
   journal = {Journal of Visual Communication and Image Representation},
   keywords = {Aerial imagery,Computer vision,Database,Detection,Infrared imagery,Low resolution images,Vehicles},
   title = {Vehicle Detection in Aerial Imagery : A small target detection benchmark},
   url = {https://hal.science/hal-01122605v2},
   year = {2015}
}

@misc{vedai_web,
   title = {Vehicle Detection in Aerial Imagery (VEDAI) : a benchmark},
   url = {https://downloads.greyc.fr/vedai/}
}


@article{Wiley2018,
   abstract = {Computer vision has been studied from many persective. It expands from raw data recording into techniques and ideas combining digital image processing, pattern recognition, machine learning and computer graphics. The wide usage has attracted many scholars to integrate with many disciplines and fields. This paper provide a survey of the recent technologies and theoretical concept explaining the development of computer vision especially related to image processing using different areas of their field application. Computer vision helps scholars to analyze images and video to obtain necessary information, understand information on events or descriptions, and scenic pattern. It used method of multi-range application domain with massive data analysis. This paper provides contribution of recent development on reviews related to computer vision, image processing, and their related studies. We categorized the computer vision mainstream into four group e.g., image processing, object recognition, and machine learning. We also provide brief explanation on the up-to-date information about the techniques and their performance.},
   author = {Victor Wiley and Thomas Lucas},
   doi = {10.29099/ijair.v2i1.42},
   issue = {1},
   journal = {International Journal of Artificial Intelligence Research},
   month = {6},
   pages = {22},
   publisher = {STMIK Dharma Wacana},
   title = {Computer Vision and Image Processing: A Paper Review},
   volume = {2},
   year = {2018}
}


@article{Mery2013,
   abstract = {Considerable research efforts in computer vision applied to food quality evaluation have been developed in the last years; however, they have been concentrated on using or developing tailored methods based on visual features that are able to solve a specific task. Nevertheless, today's computer capabilities are giving us new ways to solve complex computer vision problems. In particular, a new paradigm on machine learning techniques has emerged posing the task of recognizing visual patterns as a search problem based on training data and a hypothesis space composed by visual features and suitable classifiers. Furthermore, now we are able to extract, process, and test in the same time more image features and classifiers than before. Thus, we propose a general framework that designs a computer vision system automatically, i.e., it finds-without human interaction-the features and the classifiers for a given application avoiding the classical trial and error framework commonly used by human designers. The key idea of the proposed framework is to select-automatically-from a large set of features and a bank of classifiers those features and classifiers that achieve the highest performance. We tested our framework on eight different food quality evaluation problems yielding a classification performance of 95 % or more in every case. The proposed framework was implemented as a Matlab Toolbox available for noncommercial purposes. © 2012 Springer Science+Business Media, LLC.},
   author = {Domingo Mery and Franco Pedreschi and Alvaro Soto},
   doi = {10.1007/s11947-012-0934-2},
   issn = {19355130},
   issue = {8},
   journal = {Food and Bioprocess Technology},
   keywords = {Classification,Computer vision,Feature extraction,Feature selection,Food quality evaluation,Image analysis,Image processing,Image segmentation,Pattern recognition},
   month = {8},
   pages = {2093-2108},
   title = {Automated Design of a Computer Vision System for Visual Food Quality Evaluation},
   volume = {6},
   year = {2013}
}


@article{Matiacevich2013,
   abstract = {Background. Blueberries are considered an important source of health benefits. This work studied six blueberry cultivars: "Duke," "Brigitta", "Elliott", "Centurion", "Star," and "Jewel", measuring quality parameters such as °Brix, pH, moisture content using standard techniques and shape, color, and fungal presence obtained by computer vision. The storage conditions were time (0-21 days), temperature (4 and 15°C), and relative humidity (75 and 90%). Results. Significant differences (P<0.05) were detected between fresh cultivars in pH, °Brix, shape, and color. However, the main parameters which changed depending on storage conditions, increasing at higher temperature, were color (from blue to red) and fungal presence (from 0 to 15%), both detected using computer vision, which is important to determine a shelf life of 14 days for all cultivars. Similar behavior during storage was obtained for all cultivars. Conclusion. Computer vision proved to be a reliable and simple method to objectively determine blueberry decay during storage that can be used as an alternative approach to currently used subjective measurements.},
   author = {Silvia Matiacevich and Daniela Celis Cofré and Patricia Silva and Javier Enrione and Fernando Osorio},
   doi = {10.1155/2013/419535},
   issn = {23145765},
   journal = {International Journal of Food Science},
   publisher = {Hindawi Publishing Corporation},
   title = {Quality parameters of six cultivars of blueberry using computer vision},
   volume = {2013},
   year = {2013}
}
