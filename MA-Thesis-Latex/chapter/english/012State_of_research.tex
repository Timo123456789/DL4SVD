%!TEX root = ../thesis.tex
\chapter{State of research}
\label{ch:state_of_research}


\acrlong{DL} can be used in conjunction with remote sensing data for a variety of applications, such as land use and land cover classification, scene classification, or object recognition \cite{Zhu2017}. In addition, it can be used in hyperspectral analysis, in the interpretation of \acrshort{SAR} images, in the interpretation of high-resolution satellite images, in multimodal data fusion and in 3D reconstruction. Hyperspectral analysis and the interpretation of high-resolution satellite images are particularly noteworthy in this context. In hyperspectral analysis, for example, a \acrfull{SAE} was used to extract hierarchical features in the spectral domain \cite{Chen2014}. Similarly, supervised \acrlongpl{CNN} were successfully used for the classification of crop types \cite{Kussul2017}.

Before discussing methodological developments, the terms relevant to this work will be briefly defined. With regard to \emph{high resolution}, it should be noted that certain multispectral satellite systems such as Sentinel-1, Sentinel-2 or Landsat have comparatively low spatial resolutions (typically in the range of 10–30 m) \cite{Wieland2023}. In contrast, airborne images — such as those provided in the \acrshort{VEDAI} dataset — have a much higher resolution; for example, the pixels correspond to an area of 12.5\(\times\)12.5 cm and are therefore much better suited for detecting small objects \cite{Razakarivony2015}. \emph{Multispectral Imagery} refers to the spectral resolution of a sensor, i.e. the number of spectral bands and the range of the electromagnetic spectrum that a sensor captures \cite{Khan2018}. Sensors can record multiple bands simultaneously; a true colour image typically consists of the \Acrfull{R}, \Acrfull{G} and \Acrfull{B} bands, which can be extended by additional bands such as \acrfull{NIR} or other infrared bands. Additional indices (e.g. \acrfull{NDVI}) for analysis can be derived from such channels \cite{Wiley2018}. There is no clear, universal definition for \emph{Small Object Detection}, as the classification of ‘small’ depends on the resolution of the image; Common operationalisations measure the relative size of an object in relation to the image and describe small objects, for example, by mean relative overlap values (intersection over image area) in the range of approximately 0.08\% to 0.58\% \cite{Chen2017}.

\Acrlong{DL} plays a central role in the interpretation of high-resolution satellite images. An important example is scene classification, in which each image is automatically assigned a semantic label. Widely used areas of application include object recognition \cite{Bhagavathy2006,Cheng2016}, change detection \cite{Chen2006}, urban planning and land resource management. Typically, these tasks can be divided into the steps of feature extraction and classification. Since \Acrlong{DL} can learn more abstract and distinctive semantic features with increasing depth, it achieves significantly better classification performance compared to classical approaches; for this reason, \Acrlong{DL} is considered state of the art for scene classification problems in high-resolution satellite images \cite{Zhu2017}.

Object recognition poses a particular challenge in this context, as one or more specified ground objects such as buildings, vehicles or aircraft must not only be located but also assigned to a category. Deep convolutional neural networks (DCNNs) are preferred for this purpose because they are capable of learning highly abstract and semantically meaningful feature representations \cite{Zhu2017}. A particularly relevant field of application is traffic planning: satellite images can be used to obtain information on vehicle distribution across an entire region at a specific point in time. Snapshots of the entire road network provide valuable insights into the distribution of vehicles and offer information for areas that are not covered by conventional counting systems — mostly inductive loop detectors embedded in the road surface. Since the introduction of civilian high-resolution optical satellites such as Quickbird and Ikonos, images with a resolution of approximately one metre have been available. This has made it possible to reliably detect and correctly classify relatively small objects such as vehicles on high-resolution satellite images \cite{Eikvil2009}. Modern satellite missions such as those from Planet (50 cm/pixel) \cite{planet_labs} or the Airbus Pléiades Neo satellites (30 cm/pixel) \cite{airbus_neo} now offer even higher resolutions, which significantly expands the possibilities for the precise detection of small vehicles.

Before the breakthrough of deep neural networks, classical methods such as \Acrfull{SVM} or \Acrfull{SAE} dominated. However, hyperspectral remote sensing images showed that \Acrshort{SAE} did not achieve any obvious performance improvement over \Acrshort{SVM}; this is often explained by the fact that \acrshort{SAE} requires significantly more training data due to the large number of parameters, and the expected advantage is relativised by the effort involved in data collection \cite{Liu2017}.

With the advent of \Acrlong{DL}, \Acrshortpl{CNN} established itself for both specific and generic object recognition tasks. To improve the training process, a weakly supervised learning framework was proposed that uses a pre-trained \acrshort{CNN} and a negative bootstrap scheme to achieve rapid convergence of the detector \cite{Zhou2016}. Further work combined deep environmental features extracted from pre-trained \Acrshortpl{CNN} with classic local features such as oriented gradient histograms \cite{Dalal2005} for the reliable detection of, for example, oil tanks \cite{Zhang2015}. Two-Stage approaches have also been successfully applied: GoogLeNet was trained with different fine-tuning parameters and then used in a sliding window method for object detection \cite{Sevo2016}. The problem of varying object orientations was addressed by using combined \acrshort{CNN} layer features, which enable orientation-robust detections in a coarse localisation frame \cite{Zhu2015}.

At the same time, the use of multispectral and hyperspectral data gained in importance. Multispectral channels such as \acrshort{RGB}, \acrshort{NIR}, \Acrfull{MIR} or \Acrfull{FIR} are used, for example, in the context of autonomous driving, as infrared channels in particular allow reliable detection even in poor weather conditions \cite{Takumi2017}. In the field of vehicle detection, the panchromatic band is used for vehicle classification, while multispectral information is used to mask vegetation and shadows \cite{Eikvil2009}.

Hybrid \acrshort{CNN} models have been developed for the detection of vehicles in high-resolution satellite images. These models divide feature maps from convolutional and pooling layers into blocks of variable size in order to extract multi-scale features \cite{XueyunChen2014}. An alternative approach uses graph-based superpixel segmentation to extract image sections, which are then classified by a \acrshort{CNN} to determine whether a vehicle is present \cite{Jiang2015}.

Previous studies show that optimising hyperparameters in \acrshort{YOLO}v3  — in particular the grid size, training duration and learning rate — can improve the \acrfull{mAP} for the detection of small objects \cite{Balzer2022}. For example, in the Airbus Ship Detection dataset \cite{Airbus_Ship_Det}, adjusting the grid size and using a learning rate scheduler led to better results in the smaller object classes (0–5\% and 5–20\% of the image area, respectively) \cite{Balzer2022}. However, for datasets with larger images and a large number of objects, such as \acrshort{DOTA}, no significant improvement in \acrshort{mAP} could be achieved. These results suggest that \acrshort{YOLO}v3 can be used effectively for the detection of small objects under certain conditions, but may not be optimal for more complex multi-class scenarios \cite{Balzer2022}.

The findings complement the existing literature and emphasise that, in addition to the architecture, the choice of hyperparameters and the characteristics of the data set are also crucial for detection performance. They support the need to specifically investigate the effects of additional spectral channels and different bounding box types (axis-aligned vs. oriented) in the context of high-resolution multispectral satellite images.

Despite this progress, research questions remain unanswered. In particular, it needs to be clarified to what extent modern One-Stage detectors such as \acrshort{YOLO} benefit from the input of additional spectral channels (e.g. \Acrfull{IR}, \acrshort{NDVI}) compared to pure \acrshort{RGB} inputs. Theoretically, performance should improve with additional channels, as vegetation can be better separated (e.g., by adding \acrshort{NDVI}) and \acrshort{IR} provides additional information-rich signals. The influence of axis-aligned versus oriented bounding boxes (\acrshort{abb} vs. \acrshort{obb}) on detection performance should also be investigated, as well as the question of which individual channels improve or worsen performance.
  
This paper uses a modern \acrshort{YOLO} architecture (version 9), which may result in improved detection results and training capabilities compared to older versions such as YOLOv3. This allows the effects of additional spectral channels and optimised hyperparameters to be specifically investigated in the context of high-resolution multispectral aerial images.



