%!TEX root = ../thesis.tex
\chapter{Methodology}
\todo{Ablaufdiagramm einfügen}
\label{ch:methodology}

Um Objekte auf hochauflösenden Satellitenbildern zu detektieren, bietet sich der 'You Only Look Once' (YOLO) Algorithmus an. Dieser Algorithmus, der in der Version 9 im Jahr 2024 veröffentlicht wurde, ermöglicht eine schnelle und präzise Objekterkennung. YOLO basiert auf einer einzigen neuronalen Netzwerkarchitektur, die das Bild in Raster unterteilt und für jedes Rasterfeld Vorhersagen über die Position und Klasse von Objekten trifft. 

Die Hauptvorteile von YOLO sind seine Geschwindigkeit und Genauigkeit, die es ermöglichen, große Datensätze effizient zu analysieren. Für diese Arbeit wird YOLO verwendet, um Fahrzeuge auf Luftbildern zu detektieren und zu klassifizieren. Dabei könnten zusätzliche multispektrale Kanäle wie NIR oder IR integriert werden, um einen Vergleich zu dem reinen 3 Kanal RGB Training zu ermöglichen. Die Vergleichbarkeit kann gewährleistet werden, wenn die gleichen Trainings- und Testdaten verwendet werden, bei denen der einzige Unterschied das weitere Band ist.

\section{Preprocessing of input data}
\section{YOLOv9}
\subsection{YOLOv9u}
\subsection{YOLOv9e}
\subsection{Hyperparameter}

\section{Database}
\subsection{Vehicle Detection on Aerial Images (VEDAI) Dataset}

Das 'Vehicle Detection in Aerial Images' (VEDAI) Dataset \cite{vedai_web}  aus dem Jahr 2015 bietet sich als Datengrundlage an, da es hochauflösende Luftbilder enthält, die speziell für die Fahrzeugerkennung geeignet sind \cite{Razakarivony2015}. Es umfasst annotierte Daten, die Fahrzeuge in unterschiedlichen Szenarien, Größen und Orientierungen zeigen. Außerdem ist es ein Benchmark für die Detektion von sehr kleinen Objekten. Das Dataset enthält sowohl RGB-Bilder als auch multispektrale Daten, was es ideal für die Untersuchung der Auswirkungen zusätzlicher Kanäle wie NIR oder IR auf die Objekterkennung macht. Es sind mehr als 3700 Objekte in ungefähr 1200 Bildern annotiert. Diese Objekte sind in 9 Klassen (Boat, Camping Car, Car, Pickup, Plane, Tractor, Truck, Van und Others) unterteilt und der Hintergrund der Objekte ist abwechslungsreich, was die Robustheit des trainierten Modelles erhöht. \\
Die Auflösung der Bilder liegt bei 12.5 cm \texttimes 12.5 cm pro Pixel, was ausreichend ist um einzelne Fahrzeuge zu erkennen. Die Bilder mit einer Größe von 1024 \texttimes 1024 Pixeln sind bei einer Befliegung im Jahr 2012 in US Amerikanischen Bundesstaat Utah aufgenommen worden. 
\todo{Bsp. Bild für jede Klasse zeigen (aus Paper nehmen!; Quellenverlinkung für text und bild nicht vergessen)}

Die Datenaufbereitung umfasst Schritte wie das Unterteilen der Bilder in Trainings- und Testdaten, sowie die Aufbereitung der Annotationen für den YOLO Algorithmus. Nach diesen Schritten kann das Training auf dem High-Performance-Cluster (HPC) PALMA der Uni Münster erfolgen. Anhand der Ergebnismatrix wird dann ein Vergleich der beiden Modelle erfolgen, da der einzige Unterschied das weitere Band ist. 

\subsection{Dataset for Object deTection in Aerial Images (DOTA) 1.5}
\begin{itemize}
    \item DOTA bietet sich als pretrained Model Datengrundlage für die Permutationsexperimente an, da es viele verschieden Klassen auf Satellitenbildern enthält
    \item Bildgröße von 800 \texttimes 800 bis 20.000 \texttimes 20.000 Pixel
    \item 3 Channel (Red, Green, Blue) und Grayscale Images (Panchromatic Band von GF2 und JL1 Satelliten)
    \item Satellite Images von Google Earth und anderne Quellen
    \item \todo{Bsp. Bild für jede Klasse zeigen (aus Paper nehmen!; Quellenverlinkung für text und bild nicht vergessen); habe alle 16 Klassen für das Training genutzt, wichtig sind trotzdem nur Large Vehicle, Plane, Ship, small vehicle}
\end{itemize}


\section{Umsetzung}
\subsection{PALMA}
\begin{itemize}
    \item UV als Python Umgebung auf Palma genutzt
    \item Bash Scripte geschrieben um die Modelle auf diversen GPUS (HGX, etc) zu trainieren
\end{itemize}
\begin{itemize}
    \item Hersteller: MEGWARE\cite{palma_spec}
    \item 16.272 Cores
    \item 77.568 GB Memory
    \item 444 Nodes
    \item Processor: Intel Xeon Gold 6140 18C @ 2.30GHz (Skylake)
    \item Interconnect 100Gbit/s Intel Omni-Path
    \item GPFS Storage: 2,4 PB
    \item Linpack Performance: Rmax: 800 TFlop/sRpeak: 1,277 TFlop/s
    \item OS: Rocky Linux 9 
\end{itemize}

\subsection{Challenges Preprocessing}
\subsubsection{VEDAI Dataset Challenges}
\begin{itemize}
    \item Label müssen in yolov9 obb format konvertiert werden
    \item kleine Anzahl (7/3757) war kleiner als 0 oder größer als 1
    \item Lösung mit Exception Handling und Runden der Werte
    \item \todo{Beispielbilder einfügen}
\end{itemize}

\section{Workflow}
\subsection{Axis Aligned vs. Oriented Bounding Boxes}
\begin{itemize}
    \item Vergleich zwischen Axis Aligned udn Oriented Bounding Boxen
    \item YOLOv9 arbeitet ursprünglich nur mit aab Boxen
    \item YOLOv9u kann mit obb arbeiten, da Codebasis von YOLOv8 von Ultralytics, was obb unterstützt
    \item 
\end{itemize}
\begin{itemize}
    \item \todo{Vergleichsbilder (Schiff und Auto Vergleich) einfügen}
    \item mehr Blankspace bei axis aligned Bbs
    \item Concentration of the box on the actual object, significantly less surrounding area outlined. No overlap between bounding boxes (Bei Ship bb)
    \item 
\end{itemize}
\subsection{Channel Permutation}
\begin{itemize}
    \item Folgende Permutation werden im Rahmen der Arbeit evaluiert: RGBIR, IRGB, RIRB; RGB, RGIR, RGBNDVI, GBNDBVI
\end{itemize}
\subsection{DOTA Training}
\begin{itemize}
    \item DOTA als Pretrained Modell für Channel Permutation, map50-95 around 0.4 and training over around 800 epcohs 
    \item \todo{Result.png einfügen? oder doch sein lassen?}
\end{itemize}
\subsection{Ablation Studie}
\begin{itemize}
    \item Ablation Study für R, G, B, IR, NDVI durchgeführt
\end{itemize}


